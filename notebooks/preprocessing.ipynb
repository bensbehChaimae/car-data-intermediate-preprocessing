{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82852b2-8f15-4cae-a88d-14a1bdd71ff3",
   "metadata": {},
   "source": [
    "# $$Preprocessing\\ part :$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3331f1c0-81e9-4f05-8247-8c18ecc36c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.sql.functions import col, when, isnan, isnull, count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce6dc6-3984-4253-9e73-9d2f605c7b56",
   "metadata": {},
   "source": [
    "#### Initialize spark session :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0712087-f2e4-4132-bdff-087ffe56bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Car Price Prediction\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6972bd2-58b5-4d26-bc24-9739ba5a79e3",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c7489b-a2ee-4749-8672-60a23bfd7128",
   "metadata": {},
   "source": [
    "## Utils functions :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7ebfaf-24fa-4358-84ff-bbce7a59ace1",
   "metadata": {},
   "source": [
    "#### Load the csv : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1776b083-6372-4464-b553-1d1f85bc9ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file\n",
    "def load_data(file_path):\n",
    "    return spark.read.csv(file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e9fa36-aaf6-4695-9a82-c9214b9f0eec",
   "metadata": {},
   "source": [
    "#### Transform data to pyspark :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9678c67e-ef10-4302-9dce-9a915847831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_spark(df):\n",
    "    for column, dtype in df.dtypes:\n",
    "        if dtype == 'string':\n",
    "            df = df.withColumn(\n",
    "                column,\n",
    "                when(\n",
    "                    col(column).rlike(r'(?i)\\\\\"nan\\\\\"'),\n",
    "                    None\n",
    "                ).otherwise(col(column))\n",
    "            )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd693190-3242-4d59-99e9-549d7653b527",
   "metadata": {},
   "source": [
    "#### Drop useless columns : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6477e95-4e5b-41ef-a935-e1b38ac0f0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_useless_column(df, columns):\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    return df.drop(*columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edc4dc5-2c3d-4b27-8af2-d9595e596fc6",
   "metadata": {},
   "source": [
    "#### Save data as csv : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e140308-b96a-43f2-9346-46e7dbd0d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_csv(spark_df, file_path=\"output.csv\"):\n",
    "    \"\"\"\n",
    "    Converts a PySpark DataFrame to a Pandas DataFrame and saves it as a CSV file.\n",
    "    \"\"\"\n",
    "    pandas_df = spark_df.toPandas()\n",
    "    pandas_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1bb257-524d-4ac7-8fb8-88403a778fda",
   "metadata": {},
   "source": [
    "#### Handle missing values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d95bf47e-d445-4762-bc9c-24d9b9eedba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing(df) :\n",
    "    # Drop all the missing values :\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0805f96-9761-45be-a9c7-b2a24ac27389",
   "metadata": {},
   "source": [
    "#### To split equipments types :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58148690-5099-4757-bc40-481ae894bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_equipment(df, equipment_col=\"equipment\"):\n",
    "    for eq in equipment_types:\n",
    "        # Generate a clean column name\n",
    "        new_col = eq.lower().replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
    "        # Add column with True/False if the equipment exists\n",
    "        df = df.withColumn(\n",
    "                new_col,\n",
    "                when(lower(col(equipment_col)).contains(eq.lower()), lit(True)).otherwise(lit(False))\n",
    "            )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f83575-489a-46eb-9af8-41038b811787",
   "metadata": {},
   "source": [
    "### To label ecode categorical columns :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b13477e6-ac43-4122-834d-1b80a4fa8fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inplace_label_encode(df, columns):\n",
    "    for col in columns:\n",
    "        indexer = StringIndexer(inputCol=col, outputCol=col + \"_idx\")\n",
    "        df = indexer.fit(df).transform(df).drop(col).withColumnRenamed(col + \"_idx\", col)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aae93d-2daa-4e23-a96e-02c08d933e12",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc043d5-f276-449f-bc73-d6c69663507a",
   "metadata": {},
   "source": [
    "## Prepare Data for preprocessing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb2f9506-26dd-45d4-8081-c1fab63eb079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prepare the data for preprocessing :\n",
    "def prepare_data(file_path ) :\n",
    "    raw_data = load_data(file_path)\n",
    "    data = transform_spark(raw_data)\n",
    "    useless = ['creator' , 'source' , 'image_folder' , 'id' , 'title']\n",
    "    for col in useless : \n",
    "        data = drop_useless_column(data , col)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4169ff2d-c87a-4dc8-8055-1f2187605740",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743e5fd9-0655-4e43-838c-213e63c5985c",
   "metadata": {},
   "source": [
    "## Preprocess the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ce5b6b2-e416-443d-bbb8-879709e00e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_ingeneering(df):\n",
    "\n",
    "    # Drop all missing values : \n",
    "    data_cleaned = handle_missing(df)\n",
    " \n",
    "  \n",
    "\n",
    "    # Split publication_date column : \n",
    "    data_cleaned = data_cleaned.withColumn(\"publication_date\", F.to_timestamp(\"publication_date\", \"dd/MM/yyyy HH:mm\"))\n",
    "    data_features = data_cleaned.withColumn(\"publication_Year\", F.year(\"publication_date\")) \\\n",
    "       .withColumn(\"publication_Month\", F.month(\"publication_date\")) \\\n",
    "       .withColumn(\"publication_Day\", F.dayofmonth(\"publication_date\")) \\\n",
    "       .withColumn(\"publication_Weekday\", F.dayofweek(\"publication_date\")) \\\n",
    "       .withColumn(\"Is_Weekend\", (F.dayofweek(\"publication_date\") >= 6).cast(IntegerType())) \\\n",
    "       .withColumn(\"Days_since_posted\", F.datediff(F.current_date(), \"publication_date\"))\n",
    "    # Drop publication_date:\n",
    "    data_features = drop_useless_column(data_features, \"publication_date\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ## Split equipment column :\n",
    "    equipment_types = [\n",
    "    \"Jantes aluminium\", \"Airbags\", \"Climatisation\", \"navigation_system\",\n",
    "    \"Toit ouvrant\", \"Sièges cuir\", \"Radar de recul\", \"Caméra de recul\",\n",
    "    \"Vitres électriques\", \"ABS\", \"ESP\", \"Régulateur de vitesse\", \n",
    "    \"Limiteur de vitesse\", \"CD/MP3/Bluetooth\", \"Ordinateur de bord\", \"Verrouillage centralisé\"\n",
    "    ]\n",
    "    data_equipment = split_equipment(data_features)\n",
    "    # Drop equipment column :\n",
    "    data_equipment = drop_useless_column(data_equipment , \"equipment\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Change columns to english : \n",
    "    column_mapping = {\n",
    "    \"jantes_aluminium\": \"Alloy_wheels\",\n",
    "    \"airbags\": \"Airbags\",\n",
    "    \"climatisation\": \"Air_conditioning\",\n",
    "    \"navigation_system\": \"Navigation_system\",\n",
    "    \"toit_ouvrant\": \"Sunroof\",\n",
    "    \"sièges_cuir\": \"Leather_seats\",\n",
    "    \"radar_de_recul\": \"Parking_sensors\",\n",
    "    \"caméra_de_recul\": \"Rear_camera\",\n",
    "    \"vitres_électriques\": \"Electric_windows\",\n",
    "    \"abs\": \"ABS\",\n",
    "    \"esp\": \"ESP\",\n",
    "    \"régulateur_de_vitesse\": \"Cruise_control\",\n",
    "    \"limiteur_de_vitesse\": \"Speed_limiter\",\n",
    "    \"cd_mp3_bluetooth\": \"CD/MP3/Bluetooth\",\n",
    "    \"ordinateur_de_bord\": \"On_board_computer\",\n",
    "    \"verrouillage_centralisé\": \"Central_locking\"\n",
    "    }\n",
    "\n",
    "    for old_name, new_name in column_mapping.items():\n",
    "        data_equipment = data_equipment.withColumnRenamed(old_name, new_name)\n",
    "\n",
    "    save_as_csv(data_equipment , \"data_after_feature_inginering.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return data_equipment \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140872c1-b2ee-45d7-8a40-61cd84ee3dbb",
   "metadata": {},
   "source": [
    "## Variable encoding :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5f23068-081e-4550-8c65-3f1cb74d9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def variable_encoding(df):\n",
    "    \n",
    "    bool_cols = [\"Alloy_wheels\", \"Airbags\", \"Air_conditioning\", \"Navigation_system\", \"Sunroof\", \n",
    "                 \"Leather_seats\", \"Parking_sensors\", \"Rear_camera\", \"Electric_windows\", \"ABS\",\n",
    "                 \"ESP\", \"Cruise_control\", \"Speed_limiter\", \"CD/MP3/Bluetooth\", \"On_board_computer\", \n",
    "                 \"Central_locking\" ]\n",
    "\n",
    "    for col_name in bool_cols:\n",
    "        dt = dt.withColumn(col_name, col(col_name).cast(IntegerType()))\n",
    "    \n",
    "\n",
    "    \n",
    "    # Cast numeric columns to correct type\n",
    "    numeric_cols = [\"door_count\", \"fiscal_power\", \"mileage\", \"price\", \"year\", \n",
    "                       \"publication_Year\", \"publication_Month\", \"publication_Day\",\n",
    "                       \"Days_since_posted\"]\n",
    "    \n",
    "    for col_name in numeric_cols:\n",
    "        dt = dt.withColumn(col_name, col(col_name).cast(\"double\"))\n",
    "\n",
    "\n",
    "\n",
    "    # Categorical columns : \n",
    "    categorical_cols = [\"brand\", \"condition\", \"fuel_type\", \"model\", \"origin\", \"first_owner\",\n",
    "                        \"sector\", \"seller_city\", \"transmission\"]\n",
    "    \n",
    "    dt = inplace_label_encode(dt, categorical_cols)\n",
    "\n",
    "    save_as_csv(df , \"data_after_variable_encoding.csv\")\n",
    "\n",
    "    return dt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba93e72-bc00-427b-aa0f-e59b1ae4d1b4",
   "metadata": {},
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd0f21c-bfe3-453c-80db-95da024f63e4",
   "metadata": {},
   "source": [
    "## Main :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15e2a07a-e49f-438d-8e82-35f7fa5bb8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.sql.functions import col, when, isnan, isnull, count, lower, lit\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d91d1d9-27a2-42b2-8950-788e67ce8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() :\n",
    "    '''\n",
    "    Main function to begin data preprocessing pipeline \n",
    "    '''\n",
    "    input_file_path = \"raw.csv\"     # Raw data \n",
    "    output_file_path = \"preprocessed_data.csv\" \n",
    "\n",
    "    # Start preprocessing pipeline : \n",
    "    print(\"Starting Data preprocessing pipeline....\")\n",
    "\n",
    "\n",
    "    # Step 1 : prepare the data for preprocessing : \n",
    "    print(\"Step 1 : Loading and preparing the data ....\")\n",
    "    data = prepare_data(input_file_path)\n",
    "\n",
    "\n",
    "    # Step 2 : Features ingeneering :\n",
    "    print(\"Step 2 : Performing features ingeniering ....\")\n",
    "    data_features = features_ingeneering(data)\n",
    "\n",
    "\n",
    "    # Step 3 : Encoding variables \n",
    "    print(\"Step 3 : encoding categorical and binary column....\")\n",
    "    data_encoded = variable_encoding(data_features)\n",
    "\n",
    "    # Step 4 : Saving preprocessed data \n",
    "    print(\"Final Step : Save the preprocessed data to \", output_file_path , \"....\")\n",
    "    save_as_csv(data_encoded , output_file_path)\n",
    "\n",
    "\n",
    "    print(\"Congratulations , preprocessing is all completed now !\")\n",
    "\n",
    "\n",
    "    return data_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee829e-0b50-49a9-bcb0-88112d6b1446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
